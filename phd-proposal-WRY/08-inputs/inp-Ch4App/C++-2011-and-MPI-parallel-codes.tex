%%% LANDSCAPE BEGINS =======================================
% \pagebreak
% \clearpage
%\begin{flushleft}
%\begin{landscape}

% =========================================================
\subsection{App4-C++2011 Example Parallel Multithreading}
% =========================================================

\begin{enumerate}
	\item The C++ language offers for the first time support in implementing applications that require concurrent programming, regardless of the development platform. 
	
	\item Before the C++11 standard the multi-threaded applications were based on platform-specific extensions, like Intel TBB, OpenMP, Pthreads, etc. Portable applications are the major advantage brought by this new feature (i.e. Windows multi-threaded applications are easily ported to iPhone or Android platforms). 
	
	\item An advantage for those familiariazed with the Boost thread library is that many concepts from the standard C++11 library keep the same name and structure as the boost threads library classes.
	
	\item The C++ Standard Library includes classes for thread manipulation and synchronization, common protected data and low-level atomic operations. We will next exemplify and provide a general description of how these concepts occur in the C++11 Standard.
	
	\item REFERENCE: http://en.cppreference.com/w/cpp/thread
	
	\item COMPILATION \\
	Terminal\$ g++ -o multi-threaded.xx multi-threaded.cpp -std=c++11 -pthread -D\_GLIBCXX\_USE\_NANOSLEEP 
	
	\item EXECUTION\\
	Terminal\$ ./multi-threaded.xx 
	
\end{enumerate}
The 01-multi-threaded C++ program operations are described as follows: 
\begin{enumerate}
	
	\item The main C++ program spawn three threads.
	
	\item Thread-1 sleeps for 10 seconds.
	\item Thread-2 sleeps for  5 seconds.
	\item Thread-3 sleeps for  7 seconds.
	
	\item Thread-1, Thread-2 and Thread-3 are made to run some arbitrary computations to show that individual threads can do some actual useful work. For demonstration, we created three simple functions, one for each thread.  
	
	\item The sleep times were assigned to the threads to actually simulate real conditions where actual threads spent times equal to their sleep times when running actual computations. This is used to prove the time parallel nature in executions of threads.   
	
\end{enumerate}

% ==========================================================
\lstset{basicstyle=\footnotesize, numberstyle=\tiny\color{blue}, frame=single, numbers=left, firstnumber=1, stepnumber=1, numbersep=1pt, xleftmargin=2.0em, framexleftmargin=1.5em, xrightmargin=0.0em, breaklines=true, breakatwhitespace=false, breakindent=5pt, prebreak=\space, postbreak=\space }
% ==========================================================

\begin{lstlisting}[caption={App4-C++2011 Example Parallel Multithreading}, label=App4-C++2011 Example Parallel Multithreading]

// File: independent-parallel-threads-06.cpp
// Date : Sun Mar  8 12:15:41 MYT 2015 
// Author: WRY

// http://en.cppreference.com/w/cpp/thread

// COMPILATION
// THIS DOES NOT WORK
// g++  -o independent-parallel-threads-06.xx independent-parallel-threads-06.cpp -std=c++11 -pthread 

// THE FOLLOWING WORKS
// g++  -o independent-parallel-threads-06.xx independent-parallel-threads-06.cpp -std=c++11 -pthread -D_GLIBCXX_USE_NANOSLEEP 
// g++  -o independent-parallel-threads-06.xx independent-parallel-threads-06.cpp -std=gnu++11 -pthread -D_GLIBCXX_USE_NANOSLEEP 

// =========================================================

	#include <stdio.h>       // To use printf()
	#include <iostream>      // std::cout
	#include <thread>        // std::thread
	#include <ctime>	 // To use the C++ timer function
	#include <chrono>	 // To use the system_clock
	#include <mutex>	 // To run mutual exclusion (mutex) locking thread
	
	using namespace std;

// Global variables (shared among all threads for Read/Write)
	double result_wry_thread_01 = 0.0;
	double result_wry_thread_02 = 0.0;
	double result_wry_thread_03 = 0.0;
	double result_total = 0.0;

// ======================================================== 
void calculate_norm1(double x, double y, double z) {
// ========================================================
// OPENING THREAD
	std::thread::id this_id = std::this_thread::get_id();
	auto threadstart_time = std::chrono::high_resolution_clock::now();
	printf(" %lld Start wry_thread_01. Thread_ID = %x Hex. \n", threadstart_time, this_id);

// PROCESSING THREAD - DELAY (SLEEP) 10 SECONDS
	int sleep_seconds = 10;
	printf(" %lld PROCESSING wry_thread_01. Will sleep for %d seconds ... \n", threadstart_time, sleep_seconds);
	
	std::mutex g_display_mutex;
	g_display_mutex.lock();
	std::this_thread::sleep_for(std::chrono::seconds(sleep_seconds));
	g_display_mutex.unlock();
	
	result_wry_thread_01 = (x + y + z);

// CLOSING THREAD
	auto threadend_time = std::chrono::high_resolution_clock::now();
	auto duration_time = (threadend_time - threadstart_time);
	typedef std::chrono::duration<double> double_seconds;
	double process_seconds = std::chrono::duration_cast<double_seconds>(duration_time).count();
	printf(" %lld Ended wry_thread_01. Thread_ID = %x Hex. Thread processing time = %lf seconds = %lld ticks \n", threadend_time, this_id, process_seconds, duration_time);
}
// ======================================================== 
void calculate_norm2(double x, double y, double z) {
// ========================================================
// OPENING THREAD
	std::thread::id this_id = std::this_thread::get_id();
	auto threadstart_time = std::chrono::high_resolution_clock::now();
	printf(" %lld Start wry_thread_02. Thread_ID = %x Hex. \n", threadstart_time, this_id);

// PROCESSING THREAD - DELAY (SLEEP) 5 SECONDS
	int sleep_seconds = 5;
	printf(" %lld PROCESSING wry_thread_02. Will sleep for %d seconds ... \n", threadstart_time, sleep_seconds);
	
	std::mutex g_display_mutex;
	g_display_mutex.lock();
	std::this_thread::sleep_for(std::chrono::seconds(sleep_seconds));
	g_display_mutex.unlock();
	
	result_wry_thread_02 = (x/0.675 + 15.198*y + 0.005*z);    

// CLOSING THREAD
	auto threadend_time = std::chrono::high_resolution_clock::now();
	auto duration_time = (threadend_time - threadstart_time);
	typedef std::chrono::duration<double> double_seconds;
	double process_seconds = std::chrono::duration_cast<double_seconds>(duration_time).count();
	printf(" %lld Ended wry_thread_02. Thread_ID = %x Hex. Thread processing time = %lf seconds = %lld ticks \n", threadend_time, this_id, process_seconds, duration_time);
}
// ======================================================== 
void calculate_norm3(double x, double y, double z) {
// ========================================================
// OPENING THREAD
	std::thread::id this_id = std::this_thread::get_id();
	auto threadstart_time = std::chrono::high_resolution_clock::now();
	printf(" %lld Start wry_thread_03. Thread_ID = %x Hex. \n", threadstart_time, this_id);

// PROCESSING THREAD - DELAY (SLEEP) 7 SECONDS
	int sleep_seconds = 7;
	printf(" %lld PROCESSING wry_thread_03. Will sleep for %d seconds ... \n", threadstart_time, sleep_seconds);
	
	std::mutex g_display_mutex;
	g_display_mutex.lock();
	std::this_thread::sleep_for(std::chrono::seconds(sleep_seconds));
	g_display_mutex.unlock();
	
	result_wry_thread_03 = (2.56*x + y/1.56 + z*0.017); 

// CLOSING THREAD
	auto threadend_time = std::chrono::high_resolution_clock::now();
	auto duration_time = (threadend_time - threadstart_time);
	typedef std::chrono::duration<double> double_seconds;
	double process_seconds = std::chrono::duration_cast<double_seconds>(duration_time).count();
	printf(" %lld Ended wry_thread_03. Thread_ID = %x Hex. Thread processing time = %lf seconds = %lld ticks \n", threadend_time, this_id, process_seconds, duration_time);
}

// ========================================================
void print_current_date_time() {
// ========================================================
	time_t the_time;
	auto now = std::chrono::system_clock::now();
	the_time = std::chrono::system_clock::to_time_t(now);
	// std::cout << "Now : " << ctime(&tt) << std::endl;
	printf("Date Time: %s", ctime(&the_time));
}

// ========================================================
void time_ticks() {
// ========================================================
	auto ticks_wry = std::chrono::high_resolution_clock::now();
	printf(" %lld ", ticks_wry);
}

// ========================================================
int main(int argc, char *argv[]) {
// ========================================================

// OPENING MAIN PROGRAM MESSAGE
	auto start_time = std::chrono::high_resolution_clock::now();
	time_ticks(); print_current_date_time();
	time_ticks(); printf("Bismillah. Main thread started. \n");

// Threads are started by defining an object std::thread
// Spawn and launch three different threads runnung the same function
	std::thread 	wry_thread_01(calculate_norm1, 1.0, 2.0, 3.0);     
	std::thread 	wry_thread_02(calculate_norm2, 4.0, 5.0, 6.0);        
	std::thread 	wry_thread_03(calculate_norm3, 2.2, 3.2, 6.2);    

// join() - The function returns when the thread execution has completed.
// Synchronize all threads, pause until all threads finish execution.
	wry_thread_01.join();
	wry_thread_02.join();
	wry_thread_03.join();

// DISPLAY RESULTS OF INDIVIDUAL THREADS
	time_ticks(); printf("result_wry_thread_01 = %f \n", result_wry_thread_01);
	time_ticks(); printf("result_wry_thread_02 = %f \n", result_wry_thread_02);
	time_ticks(); printf("result_wry_thread_03 = %f \n", result_wry_thread_03);
	
	time_ticks(); printf("result_total = %f \n", result_wry_thread_01 + result_wry_thread_02 + result_wry_thread_03);

// CALCULATE TOTAL PROCESSING TIME
	auto end_time = std::chrono::high_resolution_clock::now();
	auto duration_time = (end_time - start_time);
	typedef std::chrono::duration<double> double_seconds;
	double process_seconds = std::chrono::duration_cast<double_seconds>(duration_time).count();
	time_ticks(); printf("TOTAL PROGRAM MULTI-THREADED PROCESSING TIME = %lf seconds = %lld ticks. \n", process_seconds, duration_time);

// CLOSING MAIN PROGRAM MESSAGE
	time_ticks(); print_current_date_time();
	time_ticks(); printf("Alhamdulillah. Main thread ended. \n");

return 0;
}
// ========================================================
\end{lstlisting}

\pagebreak
% =========================================================
\subsection{App4-C++2011 Execution Parallel Multithreading}

% ==========================================================
\lstset{basicstyle=\footnotesize, numberstyle=\tiny\color{blue}, frame=single, numbers=left, firstnumber=1, stepnumber=1, numbersep=1pt, xleftmargin=2.0em, framexleftmargin=1.5em, xrightmargin=0.0em, breaklines=true, breakatwhitespace=false, breakindent=5pt, prebreak=\space, postbreak=\space }
% ==========================================================

\begin{lstlisting}[caption={App4-C++2011 Execution Parallel Multithreading}, label=App4-C++2011 Execution Parallel Multithreading]

COMPILATION
===============
root@hpcompaqdk-ub1004-rtai:~/Documents/Multithreaded-C++11/test2.6# g++  -o independent-parallel-threads-06.xx independent-parallel-threads-06.cpp -std=c++11 -pthread -D_GLIBCXX_USE_NANOSLEEP 

EXECUTION
===============
root@hpcompaqdk-ub1004-rtai:~/Documents/Multithreaded-C++11/test2.6# ./independent-parallel-threads-06.xx 
1425871390235109 Date Time: Mon Mar  9 11:23:10 2015
1425871390235280 Bismillah. Main thread started. 
1425871390235345 Start wry_thread_02. Thread_ID = b6f28b70 Hex. 
1425871390235345 PROCESSING wry_thread_02. Will sleep for 5 seconds ... 
1425871390235340 Start wry_thread_01. Thread_ID = b7729b70 Hex. 
1425871390235340 PROCESSING wry_thread_01. Will sleep for 10 seconds ... 
1425871390235398 Start wry_thread_03. Thread_ID = b6727b70 Hex. 
1425871390235398 PROCESSING wry_thread_03. Will sleep for 7 seconds ... 
1425871395235469 Ended wry_thread_02. Thread_ID = b6f28b70 Hex. Thread processing time = 5.000124 seconds = 5000124 ticks 
1425871397235500 Ended wry_thread_03. Thread_ID = b6727b70 Hex. Thread processing time = 7.000102 seconds = 7000102 ticks 
1425871400235832 Ended wry_thread_01. Thread_ID = b7729b70 Hex. Thread processing time = 10.000492 seconds = 10000492 ticks 
1425871400235899 result_wry_thread_01 = 6.000000 
1425871400235922 result_wry_thread_02 = 81.945926 
1425871400235932 result_wry_thread_03 = 7.788682 
1425871400235939 result_total = 95.734608 
1425871400235963 TOTAL PROGRAM MULTI-THREADED PROCESSING TIME = 10.000849 seconds = 10000849 ticks. 
1425871400235969 Date Time: Mon Mar  9 11:23:20 2015
1425871400235995 Alhamdulillah. Main thread ended. 
root@hpcompaqdk-ub1004-rtai:~/Documents/Multithreaded-C++11/test2.6# 
*/
\end{lstlisting}

\pagebreak
% =========================================================
\subsection{App4-C++-MPI Example Parallel Multiprocessing}

\begin{enumerate}
	\item The 03-multi-processing.cpp C++ program is a program based on the OpenMPI library for multi-processing.
	
	\item It requires the installation of this OpenMPI libraries and executables on the particular platform.
	
	\begin{enumerate}
		
		\item COMPILATION:\\ 
		/usr/bin/mpic++ -o 03-multi-processing.xx 03-multi-processing.cpp -lpthread
		
		\item EXECUTION:\\
		/usr/bin/mpirun -np 10 03-multi-processing.xx | sort
		
		\item The number of processes to execute np above is 10. It can be changed by the user to any number preferred.
		
	\end{enumerate}
	
	\item Stage 1 : The program calculates the function kuntakinte(x), where x is an integer put as a very large number like 1000000 (one million).
	
	\item Stage 2 : The program calculates the function kamikamu(x), which is the cumulative sum of kuntakinta(x) which is the sum of kuntakinte(1) + kuntakinte(2) + kuntakinte(3) + .... + kuntakinte(x)
	
	\item The calculation of the function kuntakinta(x) itself is very CPU intensive. Study the program code for kuntakinte() function.
	
	\item The computation strategy for this OpenMPI program is "divide and conquer". Break the execution into np individual processes (multi-processing) to handle the large computation. Split the data regions for x into (x/np) individual tasks. This task is then assign to a process.
	
	\item For example, if x = 1,000,000 (one million), and np = 10, then each process will handle (1,000,000)/10 = 100,000 (one hundred thousand).
	
	\item The final result for kamikamu(1,000,000), as an example, must be the same whether we run with np=5, np=10, np=20 or any integer number because np is just the number of processes we choose to split the computation work.
	
	\item Yes. We have proven that it gave the same results for different values of np.
	
	\item The concept is similar to counting a very large pile (mountain) of oranges. The total count must be the same whether we hire 10 people, 50 people or 100 people to do the counting. The total sum cannot change. 
	
	\item This is what the current OpenMPI code 03-multi-processing.cpp does. The number of people (processes) to do the counting (computation) is np. Ha ha ha. Ya ya ya. Kah kah kah.
	
\end{enumerate}

% ==========================================================
\lstset{basicstyle=\footnotesize, numberstyle=\tiny\color{blue}, frame=single, numbers=left, firstnumber=1, stepnumber=1, numbersep=1pt, xleftmargin=2.0em, framexleftmargin=1.5em, xrightmargin=0.0em, breaklines=true, breakatwhitespace=false, breakindent=5pt, prebreak=\space, postbreak=\space }
% ==========================================================

\begin{lstlisting}[caption={App4-C++-MPI Example Parallel Multiprocessing}, label=App4-C++-MPI Example Parallel Multiprocessing]

// File: kamikamu-parallel.c
// Date: Thu Jan  3 21:53:17 MYT 2013
// Rev1: Mon Nov 18 03:45:54 MYT 2013
//
// This is a kamikamu() and kuntakinte() C-program for running parallel OpenMPI routines 
// that run on a local multicore computer or distributed on a computing cluster. 
//
// COMPILATION 
// /opt/openmpi/bin/mpicc -o kamikamu-parallel.x kamikamu-parallel.c 
// /usr/bin/mpicc -o kamikamu-parallel.x kamikamu-parallel.c 

// EXECUTION ON LOCAL MACHINE
// /opt/openmpi/bin/mpirun -np 10 kamikamu-parallel.x | sort
// /usr/bin/mpirun -np 10 kamikamu-parallel.x | sort

// EXECUTION ON CLUSTER MACHINE
// /opt/openmpi/bin/mpirun -np 10 -hostfile machines kamikamu-parallel.x | sort

// ========================================================
#include <math.h>     // For mathematical functions
#include <stdio.h>    // For function printf()
#include <stdlib.h>   // For function calloc()
#include <string.h>   // For function %s (printf string)
#include <time.h>     // For datetimestamp() function

// SET THE PATH FOR THIS HEADER FILE TO SUIT ITS LOCATION ON YOUR COMPUTER

// #include "/opt/openmpi/include/mpi.h"
#include "/usr/lib/openmpi/include/mpi.h"

// ========================================================
void datetimestamp() {
// ========================================================
	time_t ltime; 		/* calendar time */
	ltime=time(NULL); 	/* get current cal time */
	printf("%s",asctime(localtime(&ltime)));
}
// =========================================================
// DEFINE FUNCTION kuntakinte(n) THE FUNNY FUNCTION
// =========================================================
	unsigned long int kuntakinte(unsigned long int n) {
	unsigned long int m = 0;
	while (n != 1) {

		if ((n%2) == 0) {
			n = (n/2);        // FOR EVEN n
		} else { 
			n = (3*n) + 1 ;   // FOR ODD  n
		} 
		m = m + 1;

	// TRACE PRINT
	// printf("r = %d \tm = %d ", n, m);
	}

return (m);
}
// =========================================================
// DEFINE FUNCTION kamikamu(x) THE SUM ACCUMULATION FUNCTION
// =========================================================
	unsigned long int kamikamu(unsigned long int xstart, unsigned long int xend) {
	
	unsigned long int n; 
	unsigned long int kamikamu_sum = 0;

	for (n = xstart; n <= xend; n++) {
		kamikamu_sum = kamikamu_sum + kuntakinte(n);

		//TRACE PRINT
		//printf("kuntakinte(%d) = %d \t kamikamu(%d) = %d \n", n, kuntakinte(n), n, kamikamu_sum); 
	}    
	return (kamikamu_sum);
}
// ========================================================
int main(int argc, char **argv) {
// ========================================================
// VARIABLES FOR CALCULATION
	int intv_start, intv_end;
	unsigned long int interval_start, interval_end;
	unsigned long int sum, result;
	sum = 0;
	result = 0;
	
	double tStart, tEnd, tExecution;
	double tNow1, tNow2, tNow3;
	double step;
	char* cpu_name;
	int num_steps = 1000000;
	step = 1.0 / (double)num_steps;

// VARIABLES FOR OPENMPI ENVIRONMENT
	int procID, totProcesses;

// INITIALIZE OPENMPI ENVIRONMENT
	MPI_Init(&argc, &argv);
	MPI_Comm_size(MPI_COMM_WORLD, &totProcesses);
	MPI_Comm_rank(MPI_COMM_WORLD, &procID);
	cpu_name = (char *)calloc(80,sizeof(char));
	gethostname(cpu_name,80);

	if (procID == 0) {
		printf("(Q2.1B) Calculate kamikamu(1000000) using C-code with OpenMPI on local machine.\n");
		printf("PROGRAM STARTING: "); datetimestamp(); printf("\n");
	}

	// CALCULATE THE START AND END INTERVAL VALUES TO BE ASSIGNED TO EACH PROCESS
	intv_start = procID * (num_steps/totProcesses) +1;
	intv_end   = intv_start + (num_steps/totProcesses) -1;
	
	// THIS IS FOR THE LAST INTERVAL ONLY
	if (procID == (totProcesses-1)) {
		intv_end = num_steps;
	}

	interval_start = (unsigned long int)intv_start;
	interval_end   = (unsigned long int)intv_end;

	// DISPLAY START TIME FROM ALL PROCESSES
	tStart = MPI_Wtime();
	printf("%.16lf \tProcess-%d on %s. STARTED. Assigned range = (%d,%d) \n", MPI_Wtime()-tStart, procID, cpu_name, interval_start, interval_end);

	// EACH PROCESS WILL RUN THE AREA COMPUTATION FOR ITS OWN ASSIGNED INTERVAL (START AND END VALUES)
	tNow2 = MPI_Wtime();
	sum = kamikamu(interval_start, interval_end);
	tNow3 = MPI_Wtime();

	// DISPLAY COMPUTING TIME EXECUTED FOR EACH PROCESS
	printf("%.16lf \tProcess-%d on %s. Execution time = %.16lf \n", MPI_Wtime()-tStart, procID, cpu_name, (tNow3-tNow2));

	// DISPLAY COLLECTED PARTIAL SUM FROM EACH PROCESS
	printf("%.16lf \tProcess-%d on %s. PARTIAL SUM = %ld \n", MPI_Wtime()-tStart, procID, cpu_name, sum);

	// ACCUMULATE SUM FROM EACH PROCESS
	MPI_Reduce(&sum, &result, 1, MPI_INTEGER, MPI_SUM, 0, MPI_COMM_WORLD);

	// DISPLAY ONLY ON HEADNODE (OTHERWISE WILL RUN ON ALL NODES)
	if (procID == 0) {
		printf("%.16lf \tProcess-%d on %s. Effective Execution Time: %.16lf \n",  MPI_Wtime()-tStart, procID, cpu_name, MPI_Wtime()-tStart);
		printf("%.16lf \tProcess-%d on %s. kamikamu(1000000) = %ld \n", MPI_Wtime()-tStart, procID, cpu_name, result);
		printf("\n"); printf("PROGRAM FINISHED: "); datetimestamp();
	}
	MPI_Finalize();
return (0);
}
// ========================================================
\end{lstlisting}

\pagebreak
% =========================================================
\subsection{App4-C++-MPI Execution Parallel Multiprocessing}

% ==========================================================
\lstset{basicstyle=\footnotesize, numberstyle=\tiny\color{blue}, frame=single, numbers=left, firstnumber=1, stepnumber=1, numbersep=1pt, xleftmargin=2.0em, framexleftmargin=1.5em, xrightmargin=0.0em, breaklines=true, breakatwhitespace=false, breakindent=5pt, prebreak=\space, postbreak=\space }
% ==========================================================

\begin{lstlisting}[caption={App4-C++-MPI Execution Parallel Multiprocessing}, label=App4-C++-MPI Execution Parallel Multiprocessing]

COMPILE THE SPMD kamikamu-parallel.c C-PROGRAM
[clab50@clusterlab tutorial04]$ /opt/openmpi/bin/mpicc -o kamikamu-parallel.x kamikamu-parallel.c 

EXECUTE THE SPMD kamikamu-parallel.x EXECUTABLE (MUST HAVE -np 10) WITH sort OUTPUT 
[clab50@clusterlab tutorial04]$ /opt/openmpi/bin/mpirun -np 10 -hostfile machines ./kamikamu-parallel.x | sort

0.0000008846400306 	Process-7 on compute-3-2.local. STARTED. Assigned range = (700001,800000) 
0.0000009156065062 	Process-3 on compute-3-3.local. STARTED. Assigned range = (300001,400000) 
0.0000009223585948 	Process-8 on compute-3-3.local. STARTED. Assigned range = (800001,900000) 
0.0000009536743164 	Process-0 on compute-3-0.local. STARTED. Assigned range = (1,100000) 
0.0000009541399777 	Process-1 on compute-3-1.local. STARTED. Assigned range = (100001,200000) 
0.0000018946593627 	Process-9 on compute-3-4.local. STARTED. Assigned range = (900001,1000000) 
0.0000019473955035 	Process-6 on compute-3-1.local. STARTED. Assigned range = (600001,700000) 
0.0000019873259589 	Process-4 on compute-3-4.local. STARTED. Assigned range = (400001,500000) 
0.0000020727748051 	Process-5 on compute-3-0.local. STARTED. Assigned range = (500001,600000) 
0.0000021163141355 	Process-2 on compute-3-2.local. STARTED. Assigned range = (200001,300000) 
0.0973579536657780 	Process-0 on compute-3-0.local. Execution time = 0.0973269939422607 
0.0973799537168816 	Process-0 on compute-3-0.local. PARTIAL SUM = 10753840 
0.1112939541926607 	Process-1 on compute-3-1.local. Execution time = 0.1111660003662109 
0.1113159541273490 	Process-1 on compute-3-1.local. PARTIAL SUM = 12184824 
0.1144861163338646 	Process-2 on compute-3-2.local. Execution time = 0.1144130229949951 
0.1145081162685528 	Process-2 on compute-3-2.local. PARTIAL SUM = 12731265 
0.1205389156239107 	Process-3 on compute-3-3.local. Execution time = 0.1204419136047363 
0.1205629155738279 	Process-3 on compute-3-3.local. PARTIAL SUM = 13092861 
0.1223229473689571 	Process-6 on compute-3-1.local. Execution time = 0.1222000122070312 
0.1223449473036453 	Process-6 on compute-3-1.local. PARTIAL SUM = 13721423 
0.1263560727238655 	Process-5 on compute-3-0.local. Execution time = 0.1262848377227783 
0.1263840727042407 	Process-5 on compute-3-0.local. PARTIAL SUM = 13534059 
0.1266208846354857 	Process-7 on compute-3-2.local. Execution time = 0.1265420913696289 
0.1266438846942037 	Process-7 on compute-3-2.local. PARTIAL SUM = 13884901 
0.1267469873419032 	Process-4 on compute-3-4.local. Execution time = 0.1266419887542725 
0.1267699872842059 	Process-4 on compute-3-4.local. PARTIAL SUM = 13372761 
0.1284559223568067 	Process-8 on compute-3-3.local. Execution time = 0.1283540725708008 
0.1284809224307537 	Process-8 on compute-3-3.local. PARTIAL SUM = 14000042 
0.1290498946327716 	Process-9 on compute-3-4.local. Execution time = 0.1289429664611816 
0.1290728946914896 	Process-9 on compute-3-4.local. PARTIAL SUM = 14159263 
0.1308339537354186 	Process-0 on compute-3-0.local. Effective Execution Time: 0.1308329537278041 
0.1308569536777213 	Process-0 on compute-3-0.local. kamikamu(1000000) = 131435239 
PROGRAM FINISHED: Mon Nov 18 05:32:27 2013
PROGRAM STARTING: Mon Nov 18 05:32:27 2013
(Q2.1B) Calculate kamikamu(1000000) using C-code with OpenMPI on local machine.
[clab50@clusterlab tutorial04]$ 
*/
// ========================================================
\end{lstlisting}

% =========================================================
% \end{landscape}
% \end{flushleft}
